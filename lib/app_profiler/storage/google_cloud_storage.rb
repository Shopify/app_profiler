# frozen_string_literal: true

gem("google-cloud-storage", "~> 1.21")

require "google/cloud/storage"
require "active_support/notifications"
require "zlib"

module AppProfiler
  module Storage
    class GoogleCloudStorage < BaseStorage
      GOOGLE_SCOPE = "https://www.googleapis.com/auth/devstorage.read_write"

      class << self
        def upload(profile, _params = {})
          file = profile.file.open

          ActiveSupport::Notifications.instrument(
            "gcs_upload.app_profiler",
            file_size: file.size,
          ) do
            bucket.create_file(
              StringIO.new(gzipped_reader(file).read),
              gcs_filename(profile),
              content_type: "application/json",
              content_encoding: "gzip",
            )
          end
        end

        def enqueue_upload(profile)
          mutex.synchronize do
            process_queue_thread unless @process_queue_thread&.alive?

            @queue ||= init_queue
            begin
              @queue.push(profile, true) # non-blocking push, raises ThreadError if queue is full
            rescue ThreadError
              AppProfiler.logger.info("[AppProfiler] upload queue is full, profile discarded")
            end
          end
        end

        def reset_queue # for testing
          init_queue
          @process_queue_thread&.kill
          @process_queue_thread = nil
        end

        private

        def mutex
          @mutex ||= Mutex.new
        end

        def init_queue
          @queue = SizedQueue.new(AppProfiler.upload_queue_max_length)
        end

        def process_queue_thread
          @process_queue_thread ||= Thread.new do
            loop do
              process_queue
              sleep(AppProfiler.upload_queue_interval_secs)
            end
          end
          @process_queue_thread.priority = -1 # low priority
        end

        def process_queue
          queue = nil
          mutex.synchronize do
            break if @queue.nil? || @queue.empty?

            queue = @queue
            init_queue
          end

          return unless queue

          queue.size.times { queue.pop(false).upload }
        end

        def gcs_filename(profile)
          File.join(profile.context.to_s, profile.file.basename)
        end

        def bucket
          # The GCS gem requires the `storage.buckets.get`
          # permission to retrieve bucket details. We will set `skip_lookup` to
          # be true to skip this process.
          @bucket ||= Google::Cloud::Storage.new(
            credentials: credentials.presence,
            scope: GOOGLE_SCOPE,
            retries: 3,
          ).bucket(bucket_name, skip_lookup: true)
        end

        # We could compress everything at once using `ActiveSupport::Gzip.compress`.
        # Since we expect large files for profiles generated by stackprof,
        # compressing in chunks avoids keeping all of them in memory.
        def gzipped_reader(file)
          reader, writer = IO.pipe(binmode: true)
          Thread.new do
            writer.set_encoding("binary")
            gz = Zlib::GzipWriter.new(writer)
            # Default chunk size for gzip is 16384.
            gz.write(file.read(16384)) until file.eof?
            gz.close
          end
          reader
        end
      end
    end
  end
end
